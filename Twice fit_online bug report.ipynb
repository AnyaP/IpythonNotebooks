{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import artm\n",
    "\n",
    "path_vw = \"../VK/batches_w10d3W152win10/merged.txt\"\n",
    "#path_batches = \"../VK/bigartm_w10d3W152win10\" # основная папка с батчами\n",
    "\n",
    "path_batches = \"../VK/bigartm_1\" # первая часть батчей\n",
    "path_batches_2 = \"../VK/bigartm_2\" # вторая часть батчей\n",
    "\n",
    "# первый батч_векторайзер\n",
    "batch_vectorizer = None\n",
    "if len(glob.glob(path_batches + \"/*.batch\")) < 1:\n",
    "    batch_vectorizer = artm.BatchVectorizer(data_path=path_vw, \n",
    "                                            data_format='vowpal_wabbit', batch_size = 1000, \n",
    "                                            target_folder=path_batches)\n",
    "else:\n",
    "    batch_vectorizer = artm.BatchVectorizer(data_path=path_batches, data_format='batches')\n",
    "    \n",
    "# второй батч_векторайзер    \n",
    "batch_vectorizer_2 = None\n",
    "if len(glob.glob(path_batches + \"/*.batch\")) < 1:\n",
    "    batch_vectorizer_2 = artm.BatchVectorizer(data_path=path_vw, \n",
    "                                            data_format='vowpal_wabbit', batch_size = 1000, \n",
    "                                            target_folder=path_batches)\n",
    "else:\n",
    "    batch_vectorizer_2 = artm.BatchVectorizer(data_path=path_batches, data_format='batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_topics = []\n",
    "for i in range(0, 400):\n",
    "    topic_name = \"topic\" + str(i)\n",
    "    all_topics.append(topic_name)\n",
    "\n",
    "def prepare(model):\n",
    "    # беру словарь, собранный ранее по основной папке с батчами и лежаший в ней\n",
    "    path_batches = \"../VK/bigartm_w10d3W152win10\"\n",
    "    model.load_dictionary(dictionary_name='cooc_dictionary', \n",
    "                          dictionary_path=path_batches + '/cooc_dictionary.dict')\n",
    "    model.initialize(dictionary_name='cooc_dictionary')\n",
    "    \n",
    "    model.scores.add(artm.PerplexityScore(name='Perplexity',\n",
    "                                      use_unigram_document_model=False,\n",
    "                                      dictionary_name='cooc_dictionary'))\n",
    "\n",
    "    model.scores.add(artm.SparsityPhiScore(name='SparsityPhi'))\n",
    "\n",
    "    model.scores.add(artm.SparsityThetaScore(name='SparsityTheta'))\n",
    "\n",
    "    model.scores.add(artm.TopTokensScore(name='Top100Tokens', \n",
    "                                         num_tokens=100, \n",
    "                                         dictionary_name = 'cooc_dictionary'))\n",
    "\n",
    "    model.scores.add(artm.TopicKernelScore(name='TopicKernel', \n",
    "                                           probability_mass_threshold=0.25, \n",
    "                                           dictionary_name = 'cooc_dictionary'))\n",
    "\n",
    "def figures(model):\n",
    "    # convergence\n",
    "    x = range(model.num_phi_updates)[1:]\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(x, model.score_tracker['Perplexity'].value[1:], 'g-', linewidth=2, label=\"Perplexity\")\n",
    "    ax1.set_xlabel('Iterations count')\n",
    "    ax1.set_ylabel('Perplexity', color='g')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(x, model.score_tracker['SparsityPhi'].value[1:], 'r*', linewidth=2, label=\"Phi sparsity\")\n",
    "    ax2.plot(x, model.score_tracker['SparsityTheta'].value[1:], 'r--', linewidth=2, label=\"Theta sparsity\")\n",
    "    #ax2.plot(x, model.score_tracker['BackgroundMassScore'].value[1:], 'r^', linewidth=2, label=\"Background ratio\")\n",
    "    ax2.set_ylabel('Ratio', color='r')\n",
    "    ax2.legend(bbox_to_anchor=(1.10, 1), loc=2, borderaxespad=0.)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # interpretability\n",
    "    x = range(model.num_phi_updates)[1:]\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(x, model.score_tracker['Top100Tokens'].average_coherence[1:], 'g-', linewidth=2, label=\"size\")\n",
    "    ax1.set_xlabel('Iterations count')\n",
    "    ax1.set_ylabel('Coherence top100-win5', color='g')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(x, model.score_tracker['TopicKernel'].average_contrast[1:], 'r*', linewidth=2, label=\"contrast\")\n",
    "    ax2.plot(x, model.score_tracker['TopicKernel'].average_purity[1:], 'r--', linewidth=2, label=\"purity\")\n",
    "    ax2.set_ylabel('Ratio', color='r')\n",
    "    ax2.legend(bbox_to_anchor=(1.10, 1), loc=2, borderaxespad=0.)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model = artm.ARTM(topic_names = all_topics, cache_theta=False, reuse_theta=False, num_document_passes=10)\n",
    "prepare(model)\n",
    "\n",
    "print 'Elapsed time: {} sec.'.format(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# тут вижу графики с трэшем между запусками\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit_online(batch_vectorizer=batch_vectorizer, update_every=3)\n",
    "model.fit_online(batch_vectorizer=batch_vectorizer_2, update_every=3)\n",
    "\n",
    "print 'Elapsed time: {} sec.'.format(time.time() - start_time)\n",
    "print 'Perplexity final: {}'.format(model.score_tracker['Perplexity'].value[-1])\n",
    "figures(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
